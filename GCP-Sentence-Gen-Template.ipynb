{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Drop English Noise\n",
    "\n",
    "('English', [('of', 5), ('spoons', 4), ('six', 3), ('frog', 3), ('bags', 3), ('her', 2), ('to', 2), ('for', 2), ('scoop', 2), ('into', 2), ('these', 1), ('things', 1), ('fresh', 1), ('snow', 1), ('peas', 1), ('thick', 1), ('slabs', 1), ('blue', 1), ('and', 1), ('a', 1), ('snack', 1), ('we', 1), ('snake', 1), ('can', 1), ('three', 1), ('red', 1), ('meet', 1), ('train', 1), ('please', 0), ('call', 0), ('stella', 0), ('ask', 0), ('bring', 0), ('with', 0), ('from', 0), ('the', 0), ('store', 0), ('five', 0), ('cheese', 0), ('maybe', 0), ('brother', 0), ('bob', 0), ('also', 0), ('need', 0), ('small', 0), ('plastic', 0), ('big', 0), ('toy', 0), ('kids', 0), ('she', 0), ('will', 0), ('go', 0), ('wednesday', 0), ('at', 0), (\"station'\", 0)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASR_TYPE = \"GCP\"\n",
    "TRANSFORMATION_TYPE = \"Noise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPACE = \" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_biased_names = ['Mary', 'Patricia', 'Jennifer', 'Linda', 'Elizabeth', 'Barbara', 'Susan', 'Jessica', \\\n",
    "                        'Sarah', 'Karen', 'Nancy', 'Margaret', 'Lisa', 'Betty', 'Dorothy ', 'Sandra', 'Ashley', \\\n",
    "                       'Kimberly', 'Donna', 'Emily', 'Michelle', 'Carol', 'Amanda', 'Melissa' , 'Deborah', \\\n",
    "                       'Stephanie', 'Rebecca', 'Laura', 'Sharon', 'Cynthia']\n",
    "male_biased_names = ['James', 'John ', 'Robert ', 'Michael', 'William', 'David ', 'Richard', 'Joseph', 'Thomas', \\\n",
    "                     'Charles', 'Christopher', 'Daniel', 'Matthew', 'Anthony', 'Donald', 'Mark', 'Paul', 'Steven', \\\n",
    "                     'Andrew', 'Kenneth', 'Joshua', 'George', 'Kevin', 'Brian', 'Edward', 'Ronald', 'Timothy', \\\n",
    "                     'Jason', 'Jeffrey', 'Ryan']\n",
    "\n",
    "NAMES = list(set(female_biased_names + male_biased_names))\n",
    "NAMES = [name.strip() for name in NAMES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBS = [\"likes\", \"loves\", \"hates\", \"dislikes\", \"adores\", \"detests\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_arr_1 = ['cups', 'containers', 'straws', 'bottles', 'bags']\n",
    "action_arr_2 = ['of wool', 'of groceries', 'of concrete']\n",
    "action_arr_3 = ['of cinnamon', 'of peanut butter', 'of sugar']\n",
    "action_arr_4 = ['flags', 'decisions', 'meals']\n",
    "\n",
    "ACTIONS = { ## Non Robust\n",
    "           'bags': action_arr_2,\n",
    "           'spoons': action_arr_3,\n",
    "            ####\n",
    "            ## Robust\n",
    "           'plastic': action_arr_1,\n",
    "           'big': action_arr_4}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_ROBUST_ACTION_KEYWORDS = [\"spoons\", \"bags\"]\n",
    "ROBUST_ACTION_KEYWORDS = [\"plastic\", \"big\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_builder(action_keyword, names = NAMES, verbs = VERBS, actions = ACTIONS):\n",
    "    name = random.choice(names)\n",
    "    verb = random.choice(verbs)\n",
    "    action = random.choice(actions[action_keyword])\n",
    "    \n",
    "    sentence = name + SPACE + verb + SPACE + action_keyword + SPACE + action\n",
    "    \n",
    "    return sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_RANGE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2123\n"
     ]
    }
   ],
   "source": [
    "### Non-Robust-Word-Generation\n",
    "non_robust_sentence_set = set()\n",
    "for i in range(NUM_RANGE):\n",
    "    non_robust_action_keyword = random.choice(NON_ROBUST_ACTION_KEYWORDS)\n",
    "    non_robust_sentence_set.add(sentence_builder(action_keyword = non_robust_action_keyword))\n",
    "    \n",
    "print(len(non_robust_sentence_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2757\n"
     ]
    }
   ],
   "source": [
    "### Robust-Word-Generation\n",
    "robust_sentence_set = set()\n",
    "for i in range(NUM_RANGE):\n",
    "    robust_action_keyword = random.choice(ROBUST_ACTION_KEYWORDS)\n",
    "    robust_sentence_set.add(sentence_builder(action_keyword = robust_action_keyword))\n",
    "    \n",
    "print(len(robust_sentence_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_sentence_file(sentence_list, robust_sentences, asr_type = ASR_TYPE, \n",
    "               transfomation_type = TRANSFORMATION_TYPE):\n",
    "    if(not robust_sentences):\n",
    "        file_name = asr_type + \"/\" + asr_type + \" Non Robust Sentences - \" + transfomation_type + \".txt\"\n",
    "    else:\n",
    "        file_name = asr_type + \"/\" + asr_type + \" Robust Sentences - \" + transfomation_type + \".txt\"\n",
    "    file = open(file_name, \"w\")\n",
    "    for i in list(sentence_list):\n",
    "        file.write(i + \"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_robust_sentence_list = list(non_robust_sentence_set)\n",
    "write_sentence_file(sentence_list = non_robust_sentence_list, robust_sentences = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_sentence_list = list(robust_sentence_set)\n",
    "write_sentence_file(sentence_list = robust_sentence_list, robust_sentences = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in list(non_robust_sentence_set)[:100]:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in list(robust_sentence_set)[:100]:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
